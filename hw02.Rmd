---
title: 'STAT 420: Homework 2'
author: "Wenke Huang, Summer 2017"
date: 'Due: Monday, June 26 by 11:50 PM CDT'
output:
  html_document:
    theme: readable
    toc: yes
---

# Directions

Students are encouraged to work together on homework using the discussion boards. However, sharing, copying or providing any part of a homework solution or code is an infraction of the Universityâ€™s rules on Academic Integrity. Any violation will be punished as severely as possible.

- Your assignment must be submitted through the [submission link](https://compass2g.illinois.edu/webapps/assignment/uploadAssignment?content_id=_2649159_1&course_id=_31866_1&group_id=&mode=cpview) on **Compass 2g.** You are required to attach two (and only two) files to the *same* submission:
    - Your RMarkdown file which should be saved as `hw02_yourNetID.Rmd`. For example `hw02_dunger.Rmd`.
    - The result of knitting your RMarkdown file as `hw02_yourNetID.html`. For example `hw02_dunger.html`.
    - Any outside data provided as a `.csv` file used for the homework.
- To submit the two files, you must "zip" them together into a single `zip` file, and then submit that one file.
- Your resulting `.html` file will be considered a "report" which is the material that will determine the majority of your grade. Be sure to visibly include all `R` code and output that is relevant to answering the exercises. (You do not need to include irrelevant code you tried that resulted in error or did not answer the question correctly.)
- You are granted an unlimited number of submissions, but only the last submission *before* the deadline will be viewed and graded.
- If you use [this `.Rmd` file as a template](hw02.Rmd), be sure to remove the directions section, and consider removing `eval = FALSE` from any code chunks provided. (If you would like to run that code as part of your assignment.)
- Your `.Rmd` file should be written such that, if it is placed in a folder with any data you are asked to import, it will Knit properly without modification. 
- Unless otherwise stated, you may use `R` for each of the exercises.
- Be sure to read each exercise carefully!
- Include your Name and NetID in the final document, not only in your filenames.

# Assignment

## Exercise 1 (Using `lm`)

For this exercise we will use the `faithful` dataset. This is a default dataset in `R`, so there is no need to load it. You should use `?faithful` to learn about the background of this dataset.

**(a)** Suppose we would like to predict the duration of an eruption of [the Old Faithful geyser](http://www.yellowstonepark.com/about-old-faithful/) in [Yellowstone National Park](https://en.wikipedia.org/wiki/Yellowstone_National_Park) based on the waiting time before an eruption. Fit a simple linear model in `R` that accomplishes this task. Store the results in a variable called `faithful_model`. Output the result of calling `summary()` on `faithful_model`.

```{r}
faithful_model <- lm(eruptions ~ waiting, data = faithful)
summary(faithful_model)
```

**(b)** Output only the estimated regression coefficients. Interpret $\beta_0$ and $\hat{\beta_1}$ in the *context of the problem*. Be aware that only one of those is an estimate.

```{r}
faithful_model$coefficients
```

**(c)** Use your model to predict the duration of an eruption based on a waiting time of **80** minutes. Do you feel confident in this prediction? Briefly explain.

```{r}
predict(faithful_model, newdata = data.frame(waiting = 80))
```

**(d)** Use your model to predict the duration of an eruption based on a waiting time of **120** minutes. Do you feel confident in this prediction? Briefly explain.

```{r}
predict(faithful_model, newdata = data.frame(waiting = 120))
```

**(e)** Calculate the RSS for this model.

```{r}
sum(faithful_model$residuals^2)
# deviance(faithful_model)
```

**(f)** Create a scatterplot of the data and add the fitted regression line. Make sure your plot is well labeled and is somewhat visually appealing.

```{r, warning=FALSE}
dat = data.frame(y_true = faithful$eruptions,
                 y_hat = predict(faithful_model))
library(ggplot2)
ggplot(data = faithful) +
  geom_point(mapping = aes(x = waiting,
                           y = eruptions)) +
  geom_abline(slope = faithful_model$coefficients[2],
              intercept = faithful_model$coefficients[1])
```

**(g)** Report the value of $R^2$ for the model. Do so directly. Do not simply copy and paste the value from the full output in the console after running `summary()` in part **(a)**.

```{r}
summary(faithful_model)$r.square
```

## Exercise 2 (Writing Functions)

This exercise is a continuation of Exercise 1.

**(a)** Write a function called `get_sd_est` that calculates an estimate of $\sigma$ in one of two ways depending on input to the function. The function should take two arguments as input:

- `model_resid` - A vector of residual values from a fitted model.
- `mle` - A logical (`TRUE` / `FALSE`) variable which defaults to `FALSE`.

The function should return a single value:

- $s_e$ if `mle` is set to `FALSE`.
- $\hat{\sigma}$ if `mle` is set to `TRUE`.

```{r}
get_sd_est <- function(model_resid, mle = FALSE){
  if(mle == FALSE){
    output = sum(model_resid^2)/(length(model_resid)-2)
  } else{
    output = mean(model_resid^2)
  }
  return(output^0.5)
}
```

**(b)** Run the function `get_sd_est` on the residuals from the model in Exercise 1, with `mle` set to `FALSE`.

```{r}
get_sd_est(model_resid = faithful_model$residuals)
```

**(c)** Run the function `get_sd_est` on the residuals from the model in Exercise 1, with `mle` set to `TRUE`.

```{r}
get_sd_est(faithful_model$residuals, mle = TRUE)
```

**(d)** To check your work, output `summary(faithful_model)$sigma`. It should match at least one of **(b)** or **(c)**.

```{r}
summary(faithful_model)$sigma
```

## Exercise 3 (SLR Without Intercept)

Sometimes it can be reasonable to assume that $\beta_0$ should be 0. That is, the line should pass through the point $(0, 0)$. For example, if a car is traveling 0 miles per hour, its stopping distance should be 0! (Unlike what we saw in the book.)

We can simply define a model without an intercept,

\[
Y_i = \beta x_i + \epsilon_i.
\]

**(a)** [In the **Least Squares Approach** section of the text](http://daviddalpiaz.github.io/appliedstats/simple-linear-regression.html#least-squares-approach) you saw the calculus behind the derivation of the regression estimates, and then we performed the calculation for the `cars` dataset using `R`. Here you need to do, but not show the derivation for the slope only model. You should then use that derivation of $\hat{\beta}$ to write a function that performs the calculation for the estimate you derived. 

In summary, use the method of least squares to derive an estimate for $\beta$ using data points $(x_i, y_i)$ for $i = 1, 2, \ldots n$. Simply put, find the value of $\beta$ to minimize the function

\[
f(\beta)=\sum_{i=1}^{n}(y_{i}-\beta x_{i})^{2}.
\]

Then, write a function `get_beta_no_int` that takes input:

- `x` - A predictor variable.
- `y` - A response variable.

The function should then output the $\hat{\beta}$ you derived for a given set of data.

```{r}
get_beta_no_int <- function(x, y){
  beta = sum(x*y)/sum(x^2)
  return(beta)
}
```

**(b)** Test your function on the `faithful` data using the waiting time as `x` and the eruption length as `y`. What is the estimate for $\beta$ for this data?

```{r}
get_beta_no_int(faithful$waiting, faithful$eruptions)
```

**(c)** Check your work in `R`. The following syntax can be used to fit a model without an intercept:

```{r, eval =FALSE}
lm(response ~ 0 + predictor, data = dataset)
```

Use this to fit a model to the `faithful` data without an intercept. Output the coefficient of the fitted model. It should match your answer to **(b)**.

```{r}
lm(eruptions ~ waiting -1 , data = faithful)$coefficient
```

**(d)** *This question is optional and you **may** recieve a small number of bonus points for completing it.* Write your derivation in your `.Rmd` file using TeX. Or write your derivation by hand, scan or photograph your work, and insert it into the `.Rmd` as an image. See the RMarkdown documentation for working with images.

## Exercise 4 (Simulating SLR)

Consider the model

\[
Y_i = 3 - 7 x_i + \epsilon_i
\]

with 

\[
\epsilon_i \sim N(\mu = 0, \sigma^2 = 4)
\]

where $\beta_0 = 3$ and $\beta_1 = -7$.

Before answering the following parts, set a seed value equal to **your** UIN.

**(a)** Use `R` to simulate `n = 50` observations from the above model. You may use [the `sim_slr ` function provided in the text](http://daviddalpiaz.github.io/appliedstats/simple-linear-regression.html#simulating-slr). You should keep the arguments for `xmin` and `xmax` set to their defaults. Store the data frame this function returns in a variable of your choice. Note that this function calls $y$ `response` and $x$ `predictor`.

```{r}
uin = 671105713
set.seed(uin)

sim_slr = function(n, beta_0 = 10, beta_1 = 5, sigma = 1, xmin = 0, xmax = 10){
  x = runif(n, xmin, xmax)
  epsilon = rnorm(n, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  data.frame(predictor = x, response = y)
}
dat <- sim_slr(n = 50, beta_0 = 3, beta_1 = -7, sigma = 2)
```

**(b)** Fit a model to your simulated data. Report the estimated coefficients. Are they close to what you would expect? Briefly explain.

```{r}
model_4 <- lm(response ~ predictor, data = dat)
coef(model_4)
```

**(c)** Plot the data you simulated in part **(a)**. Add the regression line from part **(b)**. Hint: Keep the two commands in the same chunk, so `R` knows what plot to add the line to when knitting your `.Rmd` file.

```{r}
ggplot(data = dat) +
  geom_point(mapping = aes(x = predictor,
                           y = response)) +
  geom_abline(slope = coef(model_4)[2],
              intercept = coef(model_4)[1])
```

**(d)** Use `R` to repeat the process of simulating `n = 50` observations from the above model $2000$ times. Each time fit a SLR model to the data and store the value of $\hat{\beta_1}$ in a variable called `beta_hat_1`. Some hints:

- Use a `for` loop.
- Create `beta_hat_1` before writing the `for` loop. Make it a vector of length $2000$ where each element is `0`.
- Inside the body of the `for` loop, simulate the data each time. Use a variable to temporarily store this data.
- After simulating the data, use `lm()` to fit a regression. Use a variable to temporarily store this output.
- Use the `coef()` function and `[]` to extract the correct estimated coefficient.
- Use `beta_hat_1[i]` to store in elements of `beta_hat_1`.
- See the notes on [Distribution of a Sample Mean](http://daviddalpiaz.github.io/appliedstats/introduction-to-r.html#distribution-of-a-sample-mean) for some inspiration.

You can do this differently if you like. Use of these hints is not required.

```{r}
beta_hat_0 = rep(NA, 2000)
beta_hat_1 = rep(NA, 2000)
for(i in 1:2000){
  dat = sim_slr(n = 50, beta_0 = 3, beta_1 = -7, sigma = 2)
  model = lm(response ~ predictor, data = dat)
  beta_hat_0[i] <- coef(model)[1]
  beta_hat_1[i] <- coef(model)[2]
}
```

**(e)** Report the mean and standard deviation of `beta_hat_1`. Do either of these look familiar?

```{r}
mean(beta_hat_1)
sd(beta_hat_1)
```

**(f)** Plot a histogram of `beta_hat_1`. Comment on the shape of this histogram.

```{r, message=FALSE, warning =FALSE}
beta_hat_1_dat = data.frame(beta_hat_1)
ggplot(data = beta_hat_1_dat) +
  geom_histogram(mapping = aes(x = beta_hat_1),
                 color = "white")
```

## Exercise 5 (Be A Skeptic)

Consider the model

\[
Y_i = 10 + 0 x_i + \epsilon_i
\]

with

\[
\epsilon_i \sim N(\mu = 0, \sigma^2 = 1)
\]

where $\beta_0 = 10$ and $\beta_1 = 0$.

Before answering the following parts, set a seed value equal to **your** UIN.

```{r}
uin = 123456789
set.seed(uin)
```

**(a)** Use `R` to repeat the process of simulating `n = 25` observations from the above model $1500$ times. Each time fit a SLR model to the data and store the value of $\hat{\beta_1}$ in a variable called `beta_hat_1`. You may use [the `sim_slr ` function provided in the text](http://daviddalpiaz.github.io/appliedstats/simple-linear-regression.html#simulating-slr). You should keep the arguments for `xmin` and `xmax` set to their defaults. Hint: Yes $\beta_1 = 0$.

```{r}
beta_hat_0 = rep(NA, 1500)
beta_hat_1 = rep(NA, 1500)
for(i in 1:1500){
  dat = sim_slr(n = 25, beta_0 = 10, beta_1 = 0, sigma = 1)
  model = lm(response ~ predictor, data = dat)
  beta_hat_0[i] <- coef(model)[1]
  beta_hat_1[i] <- coef(model)[2]
}
```

**(b)** Plot a histogram of `beta_hat_1`. Comment on the shape of this histogram.

```{r, warning=FALSE, message=FALSE}
ggplot() +
  geom_histogram(data = data.frame(beta_hat_1),
                 mapping = aes(x = beta_hat_1),
                 color = "white")
```

**(c)** Import the data in [`skeptic.csv`](skeptic.csv) and fit a SLR model. The variable names in `skeptic.csv` follow the same convention as those returned by `sim_slr()`. Extract the fitted coefficient for $\beta_1$.

```{r}
skeptic <- read.csv("skeptic.csv")
model_53 <- lm(response ~ predictor, data = skeptic)
coef(model_53)
```

**(d)** Re-plot the histogram from **(b)**. Now add a vertical red line at the value of $\hat{\beta_1}$ in part **(c)**. To do so, you'll need to use `abline(v = c, col = "red")` where `c` is your value.

```{r}
ggplot() +
  geom_histogram(data = data.frame(beta_hat_1),
                 mapping = aes(x = beta_hat_1),
                 color = "white") +
  geom_vline(xintercept = coef(model_53)[2],
             color = "red")
```

**(e)** Your value of $\hat{\beta_1}$ in **(c)** should be positive. What proportion of the the `beta_hat_1` values are larger than your $\hat{\beta_1}$? Return this proportion, as well as this proportion multiplied by `2`.

```{r}
mean(beta_hat_1 > coef(model_53)[2])
```

**(f)** Based on your histogram and part **(e)**, do you think the [`skeptic.csv`](skeptic.csv) data could have been generated by the model given above? Briefly explain.

## Exercise 6 (Comparing Models)

For this exercise we will use the data stored in [`goalies2017.csv`](goalies2017.csv). It contains regular season (not including playoffs) career data for all 750 players in the history of the National Hockey League to play goaltender through the 2016-2017 season. The variables in the dataset are:

- `Player` - NHL Player Name
- `First` - First year of NHL career
- `Last` - Last year of NHL career
- `Active` - Total Number of Active Seasons
- `GP` - Games Played
- `GS` - Games Started
- `W` - Wins
- `L` - Losses
- `TOL` - Ties and Overtime/Shootout Losses
- `GA` - Goals Against
- `SA` - Shots Against
- `SV` - Saves
- `SV_PCT` - Save Percentage
- `GAA` - Goals Against Average
- `SO` - Shutouts
- `PIM` - Penalties in Minutes
- `MIN` - Minutes

For this exercise we will define the "Root Mean Square Error" of a model as

\[
RMSE = \sqrt{\frac{1}{n} \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2}.
\]

**(a)** Fit a model with "wins"" as the response and "minutes" as the predictor. Calculate the RMSE of this model. Also provide a scatterplot with the fitted regression line.

```{r, warning=FALSE}
goalies2017 <- read.csv("goalies2017.csv")
model_61 <- lm(W ~ MIN, data = goalies2017)
sqrt(mean(model_61$residuals^2))

ggplot(data = goalies2017) +
  geom_point(mapping = aes(x = MIN,
                           y = W)) +
  geom_abline(slope = coef(model_61)[2],
              intercept = coef(model_61)[1])
```

**(b)** Fit a model with "wins"" as the response and "goals against" as the predictor. Calculate the RMSE of this model. Also provide a scatterplot with the fitted regression line.

```{r, warning=FALSE}
model_62 <- lm(W ~ GA, data = goalies2017)
sqrt(mean(model_62$residuals^2))
ggplot(data = goalies2017) +
  geom_point(mapping = aes(x = GA,
                           y = W)) +
  geom_abline(slope = coef(model_62)[2],
              intercept = coef(model_62)[1])
```

**(c)** Fit a model with "wins"" as the response and "shutouts" as the predictors. Calculate the RMSE of this model. Also provide a scatterplot with the fitted regression line.

```{r, warning=FALSE}
model_63 <- lm(W ~ SO, data = goalies2017)
sqrt(mean(model_63$residuals^2))
ggplot(data = goalies2017) +
  geom_point(mapping = aes(x = SO,
                           y = W)) +
  geom_abline(slope = coef(model_63)[2],
              intercept = coef(model_63)[1])
```

**(d)** Based on the previous three models, which of the three predictors used is most helpful for predicting wins? Briefly explain.

**(e)** *This is not a modeling question, but it interests me.* Alas, my favorite team, the St. Louis Blues, only made it to the second round of the 2017 NHL Playoffs, despite their goalie, Jake Allen, having one of the lowest Goals Against Averages in the regular season and the playoffs. Rank the players in the `goalies2017.csv` data set by GAA from best (i.e., lowest) to worst for those with at least 150 Games Played. 

- How many goalies have played in at least 150 games? 
- Where does Jake Allen rank among those goalies in terms of Goals Against Average?
- Where does Jake Allen rank among those goalies in terms of Save Percentage? (Note that higher is better.)

```{r}
subset_dat = subset(goalies2017, GP>=150, c("Player", "GAA", "SV_PCT")) # Played in at least 150 games
nrow(subset_dat)

ordered_dat = subset_dat[order(subset_dat$GAA), ]
# row.names(ordered_dat) <- NULL
min(which(ordered_dat$Player == "Jake Allen"))

ordered_dat2 = subset_dat[order(subset_dat$SV_PCT, decreasing = TRUE), ]
# row.names(ordered_dat2) <- NULL
min(which(ordered_dat2$Player == "Jake Allen"))
```

![a](C:/users/whuang67/desktop/knit.png)
